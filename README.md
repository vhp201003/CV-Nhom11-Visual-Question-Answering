# Visual Question Answering (VQA) - Há»‡ thá»‘ng Há»i ÄÃ¡p Dá»±a trÃªn HÃ¬nh áº£nh

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng Visual Question Answering (VQA) sá»­ dá»¥ng deep learning Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i báº±ng tiáº¿ng Viá»‡t dá»±a trÃªn ná»™i dung hÃ¬nh áº£nh. Há»‡ thá»‘ng káº¿t há»£p PhoBERT (mÃ´ hÃ¬nh ngÃ´n ngá»¯ tiáº¿ng Viá»‡t) vÃ  ResNet50 (mÃ´ hÃ¬nh thá»‹ giÃ¡c mÃ¡y tÃ­nh) Ä‘á»ƒ hiá»ƒu vÃ  phÃ¢n tÃ­ch má»‘i quan há»‡ giá»¯a vÄƒn báº£n vÃ  hÃ¬nh áº£nh.

## ğŸ“‹ Má»¥c Lá»¥c

- [Tá»•ng quan](#tá»•ng-quan)
- [Kiáº¿n trÃºc mÃ´ hÃ¬nh](#kiáº¿n-trÃºc-mÃ´-hÃ¬nh)
- [YÃªu cáº§u há»‡ thá»‘ng](#yÃªu-cáº§u-há»‡-thá»‘ng)
- [HÆ°á»›ng dáº«n táº£i dá»¯ liá»‡u](#hÆ°á»›ng-dáº«n-táº£i-dá»¯-liá»‡u)
- [Xá»­ lÃ½ dá»¯ liá»‡u](#xá»­-lÃ½-dá»¯-liá»‡u)
- [HÆ°á»›ng dáº«n training](#hÆ°á»›ng-dáº«n-training)
- [HÆ°á»›ng dáº«n inference](#hÆ°á»›ng-dáº«n-inference)
- [Cáº¥u trÃºc thÆ° má»¥c](#cáº¥u-trÃºc-thÆ°-má»¥c)
- [Káº¿t quáº£](#káº¿t-quáº£)

## ğŸ¯ Tá»•ng quan

Há»‡ thá»‘ng VQA nÃ y cÃ³ kháº£ nÄƒng:
- Nháº­n Ä‘áº§u vÃ o lÃ  má»™t hÃ¬nh áº£nh vÃ  cÃ¢u há»i báº±ng tiáº¿ng Viá»‡t
- PhÃ¢n tÃ­ch ná»™i dung hÃ¬nh áº£nh báº±ng computer vision
- Hiá»ƒu ngá»¯ nghÄ©a cÃ¢u há»i tiáº¿ng Viá»‡t
- Tráº£ vá» cÃ¢u tráº£ lá»i phÃ¹ há»£p dá»±a trÃªn ná»™i dung hÃ¬nh áº£nh

**Nguá»“n dá»¯ liá»‡u gá»‘c**: [Visual QA Dataset](https://visualqa.org/download.html)

## ğŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh

### CÃ¡c thÃ nh pháº§n chÃ­nh:

1. **Image Encoder (ResNet50)**
   - TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« hÃ¬nh áº£nh
   - Output: vector Ä‘áº·c trÆ°ng 768 chiá»u

2. **Text Encoder (PhoBERT)**
   - Xá»­ lÃ½ cÃ¢u há»i tiáº¿ng Viá»‡t
   - Model: `vinai/phobert-base`
   - Output: embedding vector cho cÃ¢u há»i

3. **Cross-Attention Mechanism**
   - Káº¿t há»£p thÃ´ng tin tá»« hÃ¬nh áº£nh vÃ  cÃ¢u há»i
   - Multi-head attention vá»›i 8 heads

4. **Classifier**
   - Dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i tá»« top 1000 cÃ¢u tráº£ lá»i phá»• biáº¿n nháº¥t

## ğŸ’» YÃªu cáº§u há»‡ thá»‘ng

### Pháº§n cá»©ng:
- GPU vá»›i Ã­t nháº¥t 8GB VRAM (khuyáº¿n nghá»‹ RTX 3070 trá»Ÿ lÃªn)
- RAM: 16GB trá»Ÿ lÃªn
- á»” cá»©ng: 50GB dung lÆ°á»£ng trá»‘ng

### Pháº§n má»m:
```bash
Python >= 3.8
PyTorch >= 1.9
CUDA >= 11.0
```

### ThÆ° viá»‡n Python:
```bash
torch>=1.9.0
torchvision>=0.10.0
transformers>=4.20.0
googletrans==3.1.0a0
langdetect>=1.0.9
Pillow>=8.3.0
tqdm>=4.62.0
pandas>=1.3.0
matplotlib>=3.5.0
```

## ğŸ“¥ HÆ°á»›ng dáº«n táº£i dá»¯ liá»‡u

### BÆ°á»›c 1: Táº£i dá»¯ liá»‡u tá»« Visual QA

Truy cáº­p [https://visualqa.org/download.html](https://visualqa.org/download.html) vÃ  táº£i vá» cÃ¡c file sau:

1. **Questions**:
   - `v2_OpenEnded_mscoco_val2014_questions.json`

2. **Annotations**:
   - `v2_mscoco_val2014_annotations.json`
   - `v2_mscoco_val2014_complementary_pairs.json`

3. **Images**:
   - `val2014.zip` (hÃ¬nh áº£nh validation set)

### BÆ°á»›c 2: Cáº¥u trÃºc thÆ° má»¥c dá»¯ liá»‡u

Sau khi táº£i vá», tá»• chá»©c thÆ° má»¥c nhÆ° sau:

```
data/
â”œâ”€â”€ v2_OpenEnded_mscoco_val2014_questions.json
â”œâ”€â”€ v2_mscoco_val2014_annotations.json
â”œâ”€â”€ v2_mscoco_val2014_complementary_pairs.json
â””â”€â”€ val2014/
    â”œâ”€â”€ COCO_val2014_000000000042.jpg
    â”œâ”€â”€ COCO_val2014_000000000073.jpg
    â””â”€â”€ ...
```

### BÆ°á»›c 3: Kiá»ƒm tra dá»¯ liá»‡u

Äáº£m báº£o cÃ¡c file cÃ³ kÃ­ch thÆ°á»›c Ä‘Ãºng:
- Questions: ~25MB
- Annotations: ~50MB
- Images: ~6.2GB (40,504 hÃ¬nh áº£nh)

## ğŸ”„ Xá»­ lÃ½ dá»¯ liá»‡u

Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u Ä‘Æ°á»£c thá»±c hiá»‡n theo thá»© tá»± sau:

### 1. PhÃ¢n tÃ­ch vÃ  gá»™p dá»¯ liá»‡u (`processing_data.ipynb`)

```bash
jupyter notebook processing_data.ipynb
```

**Chá»©c nÄƒng**:
- PhÃ¢n tÃ­ch cáº¥u trÃºc cÃ¡c file JSON
- Gá»™p questions vÃ  annotations thÃ nh má»™t file duy nháº¥t
- Äá»•i tÃªn file hÃ¬nh áº£nh cho phÃ¹ há»£p
- Táº¡o file `merged_data.json`

### 2. Dá»‹ch sang tiáº¿ng Viá»‡t (`trans_script.py`)

```bash
python trans_script.py
```

**Chá»©c nÄƒng**:
- Äá»c dá»¯ liá»‡u tá»« `merged_data.json`
- Sá»­ dá»¥ng Google Translate API Ä‘á»ƒ dá»‹ch questions vÃ  answers sang tiáº¿ng Viá»‡t
- Xá»­ lÃ½ theo chunks (100 items/chunk) Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t
- CÃ³ checkpoint Ä‘á»ƒ resume khi bá»‹ giÃ¡n Ä‘oáº¡n

**Cáº¥u hÃ¬nh quan trá»ng**:
```python
CHUNK_SIZE = 100  # KÃ­ch thÆ°á»›c má»—i chunk
INPUT_FILE = "merged_data.json"
OUTPUT_DIR = "translated_chunks"
```

### 3. Sá»­a lá»—i vÃ  hoÃ n thiá»‡n dá»¯ liá»‡u (`fix_data_script.py`)

```bash
python fix_data_script.py
```

**Chá»©c nÄƒng**:
- Kiá»ƒm tra vÃ  sá»­a cÃ¡c cÃ¢u chÆ°a Ä‘Æ°á»£c dá»‹ch Ä‘Ãºng
- Sá»­ dá»¥ng `langdetect` Ä‘á»ƒ phÃ¡t hiá»‡n ngÃ´n ngá»¯
- Dá»‹ch láº¡i cÃ¡c pháº§n chÆ°a hoÃ n thiá»‡n
- Táº¡o file cuá»‘i cÃ¹ng `output_merged_data_final.json`

### 4. Output cuá»‘i cÃ¹ng

Sau khi hoÃ n thÃ nh, báº¡n sáº½ cÃ³:
- `output_merged_data_final.json`: Dá»¯ liá»‡u questions/answers tiáº¿ng Viá»‡t
- `filtered_images/`: ThÆ° má»¥c chá»©a hÃ¬nh áº£nh Ä‘Ã£ Ä‘Æ°á»£c lá»c

## ğŸš€ HÆ°á»›ng dáº«n Training

### 1. Chuáº©n bá»‹ mÃ´i trÆ°á»ng

```bash
# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Kiá»ƒm tra GPU
python -c "import torch; print(torch.cuda.is_available())"
```

### 2. Cáº¥u hÃ¬nh training (`visual-question-answering-vqa.ipynb`)

Má»Ÿ notebook vÃ  Ä‘iá»u chá»‰nh cÃ¡c thÃ´ng sá»‘ trong pháº§n Config:

```python
# ===== Config =====
IMAGE_DIR = 'filtered_images'  # ÄÆ°á»ng dáº«n thÆ° má»¥c áº£nh
JSON_PATH = 'output_merged_data_final.json'  # File dá»¯ liá»‡u
PHOBERT_NAME = 'vinai/phobert-base'
BATCH_SIZE = 64         # Äiá»u chá»‰nh theo GPU
NUM_EPOCHS = 5          # Sá»‘ epoch training
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
TRAIN_SPLIT = 0.8       # Tá»· lá»‡ train/validation
TOP_K_ANSWERS = 1000    # Sá»‘ lÆ°á»£ng cÃ¢u tráº£ lá»i candidate
```

### 3. Khá»Ÿi cháº¡y training

```bash
# Cháº¡y toÃ n bá»™ notebook
jupyter notebook visual-question-answering-vqa.ipynb

# Hoáº·c cháº¡y script
python -c "exec(open('visual-question-answering-vqa.ipynb').read())"
```

### 4. Theo dÃµi quÃ¡ trÃ¬nh training

Model sáº½ in ra thÃ´ng tin sau má»—i epoch:
```
[Epoch 1/5] Train Loss: 2.3456 | Val Loss: 2.1234 | Val Accuracy: 23.45%
[Epoch 2/5] Train Loss: 1.9876 | Val Loss: 1.8765 | Val Accuracy: 31.23%
...
```

### 5. LÆ°u model

Model Ä‘Æ°á»£c tá»± Ä‘á»™ng lÆ°u sau khi training:
- `vqa_model_final.pt`: Model weights
- `training_history.csv`: Lá»‹ch sá»­ training

## ğŸ”® HÆ°á»›ng dáº«n Inference

### 1. Load model Ä‘Ã£ train

```python
from transformers import AutoTokenizer, AutoModel
import torch
from PIL import Image
import torchvision.transforms as transforms

# Load model
model = VQAModel(num_answers=1000)
model.load_state_dict(torch.load('vqa_model_final.pt'))
model.eval()

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')
```

### 2. Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘áº§u vÃ o

```python
# Transform cho hÃ¬nh áº£nh
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])

# Load vÃ  preprocess hÃ¬nh áº£nh
image = Image.open('path/to/image.jpg').convert('RGB')
image_tensor = transform(image).unsqueeze(0)

# Tokenize cÃ¢u há»i
question = "CÃ³ bao nhiÃªu ngÆ°á»i trong hÃ¬nh?"
q_tokens = tokenizer(question, padding='max_length', 
                    truncation=True, max_length=32, 
                    return_tensors='pt')
```

### 3. Thá»±c hiá»‡n inference

```python
with torch.no_grad():
    logits = model(image_tensor, q_tokens)
    pred_idx = logits.argmax(dim=1).item()
    answer = idx_to_answer[pred_idx]
    print(f"CÃ¢u tráº£ lá»i: {answer}")
```

### 4. Demo interactive

Sá»­ dá»¥ng function cÃ³ sáºµn trong notebook:

```python
# Test vá»›i áº£nh ngáº«u nhiÃªn
test_random_sample(model, dataset, tokenizer, transform, idx_to_answer, show_image=True)

# Test vá»›i áº£nh tá»± chá»n vÃ  Ä‘áº·t nhiá»u cÃ¢u há»i
test_random_image_with_questions(model, tokenizer, transform, idx_to_answer)
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
CV-Nhom11/
â”œâ”€â”€ README.md                                    # File hÆ°á»›ng dáº«n nÃ y
â”œâ”€â”€ processing_data.ipynb                        # Notebook xá»­ lÃ½ dá»¯ liá»‡u ban Ä‘áº§u
â”œâ”€â”€ trans_script.py                             # Script dá»‹ch sang tiáº¿ng Viá»‡t
â”œâ”€â”€ fix_data_script.py                          # Script sá»­a lá»—i dá»¯ liá»‡u
â”œâ”€â”€ visual-question-answering-vqa.ipynb         # Notebook training vÃ  inference
â”œâ”€â”€ requirements.txt                            # Dependencies
â”œâ”€â”€ data/                                       # ThÆ° má»¥c dá»¯ liá»‡u gá»‘c
â”‚   â”œâ”€â”€ v2_OpenEnded_mscoco_val2014_questions.json
â”‚   â”œâ”€â”€ v2_mscoco_val2014_annotations.json
â”‚   â”œâ”€â”€ v2_mscoco_val2014_complementary_pairs.json
â”‚   â””â”€â”€ val2014/
â”œâ”€â”€ translated_chunks/                          # Chunks dá»¯ liá»‡u Ä‘Ã£ dá»‹ch
â”œâ”€â”€ filtered_images/                            # HÃ¬nh áº£nh Ä‘Ã£ lá»c
â”œâ”€â”€ merged_data.json                           # Dá»¯ liá»‡u gá»™p ban Ä‘áº§u
â”œâ”€â”€ output_merged_data_final.json              # Dá»¯ liá»‡u cuá»‘i cÃ¹ng (tiáº¿ng Viá»‡t)
â”œâ”€â”€ vqa_model_final.pt                         # Model Ä‘Ã£ train
â””â”€â”€ training_history.csv                       # Lá»‹ch sá»­ training
```

## ğŸ“Š Káº¿t quáº£

### Hiá»‡u suáº¥t mÃ´ hÃ¬nh:
- **Dataset**: ~40,000 cáº·p hÃ¬nh áº£nh-cÃ¢u há»i-Ä‘Ã¡p Ã¡n
- **Top-1000 answers accuracy**: ~35-45% (tÃ¹y thuá»™c vÃ o sá»‘ epoch)
- **Training time**: ~2-4 giá» trÃªn GPU RTX 3070
- **Inference time**: ~100ms/sample

### Má»™t sá»‘ vÃ­ dá»¥ káº¿t quáº£:

| HÃ¬nh áº£nh | CÃ¢u há»i | Dá»± Ä‘oÃ¡n | Ground Truth |
|----------|---------|---------|--------------|
| ğŸ  | CÃ³ bao nhiÃªu cá»­a sá»•? | 2 | 2 |
| ğŸ• | Con váº­t nÃ y lÃ  gÃ¬? | chÃ³ | chÃ³ |
| ğŸš— | MÃ u xe lÃ  gÃ¬? | Ä‘á» | Ä‘á» |

### Háº¡n cháº¿:
- Äá»™ chÃ­nh xÃ¡c cÃ²n háº¡n cháº¿ do dá»¯ liá»‡u dá»‹ch mÃ¡y
- Má»™t sá»‘ cÃ¢u tráº£ lá»i bá»‹ nhiá»…u do lá»—i dá»‹ch
- Model chá»‰ cÃ³ thá»ƒ tráº£ lá»i trong top-1000 answers

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p:

1. **CUDA out of memory**:
   ```bash
   # Giáº£m batch size
   BATCH_SIZE = 32  # hoáº·c 16
   ```

2. **Google Translate API limit**:
   ```bash
   # ThÃªm delay giá»¯a cÃ¡c request
   time.sleep(1)
   ```

3. **File not found**:
   ```bash
   # Kiá»ƒm tra Ä‘Æ°á»ng dáº«n
   ls -la data/
   ```

## ğŸ¤ ÄÃ³ng gÃ³p

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi nhÃ³m 11 - mÃ´n Computer Vision. ChÃ o má»«ng cÃ¡c Ä‘Ã³ng gÃ³p Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t vÃ  tÃ­nh nÄƒng cá»§a há»‡ thá»‘ng.

## ğŸ“ License

Dá»± Ã¡n nÃ y sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u.

---

**ChÃºc báº¡n thÃ nh cÃ´ng vá»›i dá»± Ã¡n VQA! ğŸ‰**

*Náº¿u gáº·p váº¥n Ä‘á», hÃ£y táº¡o issue hoáº·c liÃªn há»‡ vá»›i nhÃ³m phÃ¡t triá»ƒn.*
